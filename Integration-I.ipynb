{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "272ec4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35444b",
   "metadata": {},
   "source": [
    "### Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f492c7",
   "metadata": {},
   "source": [
    "* left_iris=[474,475,476,477]\n",
    "* right_iris=[469,270,471,472]\n",
    "* iris=[474,475,476,477,469,470,471,472]\n",
    "* left_eyes1=[386,374,362,263]\n",
    "* right_eyes1=[159,145,133,33] \n",
    "* lips = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 61, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 78]\n",
    "* left_eyes = [263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388, 387, 386, 385, 384, 398, 362]\n",
    "* right_eyes = [33, 7, 163, 144, 145, 153, 154, 155, 133, 246, 161, 160, 159, 158, 157, 173, 133]\n",
    "* lips1 = [0,17,61,291]\n",
    "* right_eyes1 = [159, 145, 133, 33] \n",
    "* left_eyes1 = [386, 374, 362, 263]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a5925",
   "metadata": {},
   "source": [
    "# Global Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f46bbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global\n",
    "path=\"E:/ML/KLEOS_Hackathon/frames/truth_frames/\"\n",
    "LIP_CONTRACTION_RATIO = .35 \n",
    "EYE_ASPECT_RATIO = 0.15\n",
    "\n",
    "img = cv2.imread(path+\"120.jpg\");\n",
    "height, width, _ = img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbfb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4313e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rajshree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Samruddhi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249e032",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a723d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(x,y):\n",
    "    return math.dist(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb60756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_eye_gaze(img,gray):\n",
    "    for facial_landmarks in gray.multi_face_landmarks:\n",
    "        height, width, _ = img.shape\n",
    "        pt1 = facial_landmarks.landmark[476]\n",
    "        x1 = int(pt1.x * width)\n",
    "        y1 = int(pt1.y * height)\n",
    "        pt2= facial_landmarks.landmark[362]\n",
    "        x2 = int(pt2.x * width)\n",
    "        y2 = int(pt2.y * height)\n",
    "#         print(dis((x1,y1),(x2,y2)))\n",
    "        return dis((x1,y1),(x2,y2))\n",
    "\n",
    "def R_eye_gaze(img,gray):\n",
    "    for facial_landmarks in gray.multi_face_landmarks:\n",
    "        height, width, _ = img.shape\n",
    "        pt1 = facial_landmarks.landmark[474]\n",
    "        x1 = int(pt1.x * width)\n",
    "        y1 = int(pt1.y * height)\n",
    "        pt2= facial_landmarks.landmark[263]\n",
    "        x2 = int(pt2.x * width)\n",
    "        y2 = int(pt2.y * height)\n",
    "#         print(dis((x1,y1),(x2,y2)))\n",
    "        return dis((x1,y1),(x2,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ed2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for i in range(518,529):\n",
    "    img = cv2.imread(\"E:/ML/KLEOS_Hackathon/mystuff/truth/face\"+str(i)+\".jpg\")\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "    rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb_image)\n",
    "#     print(\"Frame\"+str(i))\n",
    "    x=L_eye_gaze(img,result)\n",
    "    y=R_eye_gaze(img,result)\n",
    "#     print(abs(x-y))\n",
    "    mylist.append(abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca63ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5a318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Samruddhi Tatiwar ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c101d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_ratio(top, bottom, right, left):\n",
    "    height=dis([top.x, top.y], [bottom.x, bottom.y])\n",
    "    width=dis([right.x, right.y], [left.x, left.y])\n",
    "    return height/width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11bee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204ce5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45feb662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628302c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a806122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lip_ratio(result):\n",
    "    for facial_landmarks in result.multi_face_landmarks:\n",
    "        pt_bottom = facial_landmarks.landmark[17]\n",
    "        x_bottom = int(pt_bottom.x * width)\n",
    "        y_bottom = int(pt_bottom.y * height)\n",
    "        pt_top = facial_landmarks.landmark[0]\n",
    "        x_top = int(pt_top.x * width)\n",
    "        y_top = int(pt_top.y * height)\n",
    "        pt_left = facial_landmarks.landmark[61]\n",
    "        x_left = int(pt_left.x * width)\n",
    "        y_left = int(pt_left.y * height)\n",
    "        pt_right = facial_landmarks.landmark[291]\n",
    "        x_right = int(pt_right.x * width)\n",
    "        y_right = int(pt_right.y * height)\n",
    "        # aspect ratio\n",
    "        h = math.dist((x_bottom, y_bottom),(x_top, y_top))\n",
    "        w = math.dist((x_left, y_left),(x_right, y_right))\n",
    "        return h/w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79fb83cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "# truth data analysis\n",
    "def get_emotion(img,i):\n",
    "    p=path+str(i)+\".jpg\"\n",
    "    result=DeepFace.analyze(p,actions=('emotion'),silent=True)\n",
    "    return result[0]['dominant_emotion']\n",
    "    \n",
    "emotion=get_emotion(img,120)\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d463b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec656e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b92b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b81a60",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcaa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in os.listdire(path):\n",
    "    img = cv2.imread(path+str(count)+\".jpg\")\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "    rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb_image)\n",
    "    print(\"Frame: \",i)\n",
    "    # print(get_lip_ratio(result))\n",
    "    if get_lip_ratio(result) < LIP_CONTRACTION_RATIO:\n",
    "        print(\"Lip Compression\")\n",
    "    else:\n",
    "        print(\"No Compression\")\n",
    "    count++;\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
